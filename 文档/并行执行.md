# 并行执行

- hive.exec.parallel

	Default Value: false

	Whether to execute jobs in parallel.  Applies to MapReduce jobs that can run in parallel, for example jobs processing different source tables before a join.  As of Hive 0.14 , also applies to move tasks that can run in parallel, for example moving files to insert targets during multi-insert.

	是否在并行模式下运行 jobs

	适用于可以在并行模式下运行的 mr jobs. 例如，在 join 前，处理不同的源表

	从 Hive 0.14 开始，也适用于可以在并行模式下运行移动任务，例如，在 multi-insert 中，移动文件以插入目标表

	【在并行模式下会耗费更多资源】

- hive.exec.parallel.thread.number

	Default Value: 8

	How many jobs at most can be executed in parallel.

	在并行模式下最多可以运行的 jobs 数量。


```sql
-- 使用 movies_len ml-25m.zip 数据集
create table t1_1(uid int, c1 int);
create table t1_2(mid int, c1 int);

from ratings t1
insert overwrite table t1_1
select t1.uid, sum(rating) c1 group by t1.uid
insert overwrite table t1_2
select t1.mid, sum(rating) c1 group by t1.mid;

0: jdbc:hive2://zgg-server:10000> set hive.exec.parallel=true;

-- 观察stage运行时间
from tb_ratings t1
insert overwrite table t1_1
select t1.uid, sum(rating) c1 group by t1.uid
insert overwrite table t1_2
select t1.mid, sum(rating) c1 group by t1.mid;
...
INFO  : Query ID = root_20240114053227_807724f3-b1bc-4b25-aa3a-27bf8f2feb15
INFO  : Total jobs = 4
INFO  : Launching Job 1 out of 4
INFO  : Starting task [Stage-2:MAPRED] in parallel
INFO  : Number of reduce tasks not specified. Estimated from input data size: 1
INFO  : In order to change the average load for a reducer (in bytes):
INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>
INFO  : In order to limit the maximum number of reducers:
INFO  :   set hive.exec.reducers.max=<number>
INFO  : In order to set a constant number of reducers:
INFO  :   set mapreduce.job.reduces=<number>
INFO  : number of splits:1
INFO  : Submitting tokens for job: job_1705209094457_0006
INFO  : Executing with tokens: []
INFO  : The url to track the job: http://zgg-server:8088/proxy/application_1705209094457_0006/
INFO  : Starting Job = job_1705209094457_0006, Tracking URL = http://zgg-server:8088/proxy/application_1705209094457_0006/
INFO  : Kill Command = /opt/hadoop-3.3.6/bin/mapred job  -kill job_1705209094457_0006
INFO  : Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1
INFO  : 2024-01-14 05:32:40,834 Stage-2 map = 0%,  reduce = 0%
INFO  : 2024-01-14 05:32:52,452 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 3.87 sec
INFO  : 2024-01-14 05:33:02,990 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 7.4 sec
INFO  : MapReduce Total cumulative CPU time: 7 seconds 400 msec
INFO  : Ended Job = job_1705209094457_0006
INFO  : Starting task [Stage-0:MOVE] in serial mode
INFO  : Loading data to table default.t1_1 from hdfs://zgg-server:8020/user/hive/warehouse/t1_1/.hive-staging_hive_2024-01-14_05-32-27_284_289019426179755079-2/-ext-10000
INFO  : Launching Job 2 out of 4
INFO  : Starting task [Stage-4:MAPRED] in parallel
INFO  : Launching Job 3 out of 4
INFO  : Starting task [Stage-5:MAPRED] in parallel
INFO  : Number of reduce tasks determined at compile time: 1
INFO  : In order to change the average load for a reducer (in bytes):
INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>
INFO  : In order to limit the maximum number of reducers:
INFO  :   set hive.exec.reducers.max=<number>
INFO  : In order to set a constant number of reducers:
INFO  :   set mapreduce.job.reduces=<number>
INFO  : Number of reduce tasks not specified. Estimated from input data size: 1
INFO  : In order to change the average load for a reducer (in bytes):
INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>
INFO  : In order to limit the maximum number of reducers:
INFO  :   set hive.exec.reducers.max=<number>
INFO  : In order to set a constant number of reducers:
INFO  :   set mapreduce.job.reduces=<number>
INFO  : number of splits:1
INFO  : number of splits:1
INFO  : Submitting tokens for job: job_1705209094457_0008
INFO  : Executing with tokens: []
INFO  : The url to track the job: http://zgg-server:8088/proxy/application_1705209094457_0008/
INFO  : Starting Job = job_1705209094457_0008, Tracking URL = http://zgg-server:8088/proxy/application_1705209094457_0008/
INFO  : Kill Command = /opt/hadoop-3.3.6/bin/mapred job  -kill job_1705209094457_0008
INFO  : Submitting tokens for job: job_1705209094457_0007
INFO  : Executing with tokens: []
INFO  : The url to track the job: http://zgg-server:8088/proxy/application_1705209094457_0007/
INFO  : Starting Job = job_1705209094457_0007, Tracking URL = http://zgg-server:8088/proxy/application_1705209094457_0007/
INFO  : Kill Command = /opt/hadoop-3.3.6/bin/mapred job  -kill job_1705209094457_0007
INFO  : Hadoop job information for Stage-4: number of mappers: 1; number of reducers: 1
INFO  : 2024-01-14 05:33:20,902 Stage-4 map = 0%,  reduce = 0%
INFO  : 2024-01-14 05:33:29,375 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 1.54 sec
INFO  : 2024-01-14 05:33:38,780 Stage-4 map = 100%,  reduce = 100%, Cumulative CPU 4.43 sec
INFO  : MapReduce Total cumulative CPU time: 4 seconds 430 msec
INFO  : Ended Job = job_1705209094457_0007
INFO  : Hadoop job information for Stage-5: number of mappers: 1; number of reducers: 1
INFO  : 2024-01-14 05:33:56,755 Stage-5 map = 0%,  reduce = 0%
INFO  : 2024-01-14 05:34:05,321 Stage-5 map = 100%,  reduce = 0%, Cumulative CPU 1.76 sec
INFO  : 2024-01-14 05:34:15,845 Stage-5 map = 100%,  reduce = 100%, Cumulative CPU 5.38 sec
INFO  : MapReduce Total cumulative CPU time: 5 seconds 380 msec
INFO  : Ended Job = job_1705209094457_0008
INFO  : Starting task [Stage-1:MOVE] in serial mode
INFO  : Loading data to table default.t1_2 from hdfs://zgg-server:8020/user/hive/warehouse/t1_2/.hive-staging_hive_2024-01-14_05-32-27_284_289019426179755079-2/-ext-10002
INFO  : Launching Job 4 out of 4
INFO  : Starting task [Stage-7:MAPRED] in parallel
INFO  : Number of reduce tasks determined at compile time: 1
INFO  : In order to change the average load for a reducer (in bytes):
INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>
INFO  : In order to limit the maximum number of reducers:
INFO  :   set hive.exec.reducers.max=<number>
INFO  : In order to set a constant number of reducers:
INFO  :   set mapreduce.job.reduces=<number>
INFO  : number of splits:1
INFO  : Submitting tokens for job: job_1705209094457_0009
INFO  : Executing with tokens: []
INFO  : The url to track the job: http://zgg-server:8088/proxy/application_1705209094457_0009/
INFO  : Starting Job = job_1705209094457_0009, Tracking URL = http://zgg-server:8088/proxy/application_1705209094457_0009/
INFO  : Kill Command = /opt/hadoop-3.3.6/bin/mapred job  -kill job_1705209094457_0009
INFO  : Hadoop job information for Stage-7: number of mappers: 1; number of reducers: 1
INFO  : 2024-01-14 05:34:33,109 Stage-7 map = 0%,  reduce = 0%
INFO  : 2024-01-14 05:34:40,488 Stage-7 map = 100%,  reduce = 0%, Cumulative CPU 1.5 sec
INFO  : 2024-01-14 05:34:50,954 Stage-7 map = 100%,  reduce = 100%, Cumulative CPU 4.67 sec
INFO  : MapReduce Total cumulative CPU time: 4 seconds 670 msec
INFO  : Ended Job = job_1705209094457_0009
INFO  : Starting task [Stage-3:STATS] in parallel
INFO  : Starting task [Stage-6:STATS] in parallel
INFO  : Executing stats task
INFO  : Executing stats task
INFO  : Table default.t1_1 stats: [numFiles=1, numRows=6040, totalSize=53765, rawDataSize=47725, numFilesErasureCoded=0]
INFO  : Table default.t1_2 stats: [numFiles=1, numRows=3706, totalSize=32221, rawDataSize=28515, numFilesErasureCoded=0]
INFO  : MapReduce Jobs Launched: 
INFO  : Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 7.4 sec   HDFS Read: 21614724 HDFS Write: 158651 HDFS EC Read: 0 SUCCESS
INFO  : Stage-Stage-4: Map: 1  Reduce: 1   Cumulative CPU: 4.43 sec   HDFS Read: 15059 HDFS Write: 1695 HDFS EC Read: 0 SUCCESS
INFO  : Stage-Stage-5: Map: 1  Reduce: 1   Cumulative CPU: 5.38 sec   HDFS Read: 114618 HDFS Write: 33595 HDFS EC Read: 0 SUCCESS
INFO  : Stage-Stage-7: Map: 1  Reduce: 1   Cumulative CPU: 4.67 sec   HDFS Read: 15059 HDFS Write: 1695 HDFS EC Read: 0 SUCCESS
INFO  : Total MapReduce CPU Time Spent: 21 seconds 880 msec
INFO  : Completed executing command(queryId=root_20240114053227_807724f3-b1bc-4b25-aa3a-27bf8f2feb15); Time taken: 144.9 seconds
9,746 rows affected (145.311 seconds)
```

```sql
0: jdbc:hive2://zgg-server:10000> set hive.exec.parallel=false;

from ratings t1
insert overwrite table t1_1
select t1.uid, sum(rating) c1 group by t1.uid
insert overwrite table t1_2
select t1.mid, sum(rating) c1 group by t1.mid;
...
INFO  : Query ID = root_20240114052706_5444ca32-0f8b-4990-bd03-c748f6cfa8a2
INFO  : Total jobs = 4
INFO  : Launching Job 1 out of 4
INFO  : Starting task [Stage-2:MAPRED] in serial mode
INFO  : Number of reduce tasks not specified. Estimated from input data size: 3
INFO  : In order to change the average load for a reducer (in bytes):
INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>
INFO  : In order to limit the maximum number of reducers:
INFO  :   set hive.exec.reducers.max=<number>
INFO  : In order to set a constant number of reducers:
INFO  :   set mapreduce.job.reduces=<number>
INFO  : number of splits:3
INFO  : Submitting tokens for job: job_1705209094457_0002
INFO  : Executing with tokens: []
INFO  : The url to track the job: http://zgg-server:8088/proxy/application_1705209094457_0002/
INFO  : Starting Job = job_1705209094457_0002, Tracking URL = http://zgg-server:8088/proxy/application_1705209094457_0002/
INFO  : Kill Command = /opt/hadoop-3.3.6/bin/mapred job  -kill job_1705209094457_0002
INFO  : Hadoop job information for Stage-2: number of mappers: 3; number of reducers: 3
INFO  : 2024-01-14 05:27:25,190 Stage-2 map = 0%,  reduce = 0%
INFO  : 2024-01-14 05:28:12,164 Stage-2 map = 22%,  reduce = 0%, Cumulative CPU 22.93 sec
INFO  : 2024-01-14 05:28:13,272 Stage-2 map = 44%,  reduce = 0%, Cumulative CPU 24.85 sec
INFO  : 2024-01-14 05:28:14,348 Stage-2 map = 56%,  reduce = 0%, Cumulative CPU 25.3 sec
INFO  : 2024-01-14 05:28:47,096 Stage-2 map = 78%,  reduce = 0%, Cumulative CPU 36.17 sec
INFO  : 2024-01-14 05:28:48,121 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 38.15 sec
INFO  : 2024-01-14 05:28:54,751 Stage-2 map = 100%,  reduce = 67%, Cumulative CPU 43.47 sec
INFO  : 2024-01-14 05:29:08,199 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 54.56 sec
INFO  : MapReduce Total cumulative CPU time: 54 seconds 560 msec
INFO  : Ended Job = job_1705209094457_0002
INFO  : Starting task [Stage-0:MOVE] in serial mode
INFO  : Loading data to table default.t1_1 from hdfs://zgg-server:8020/user/hive/warehouse/t1_1/.hive-staging_hive_2024-01-14_05-27-06_406_5256501147906119415-2/-ext-10000
INFO  : Launching Job 2 out of 4
INFO  : Starting task [Stage-4:MAPRED] in serial mode
INFO  : Number of reduce tasks determined at compile time: 1
INFO  : In order to change the average load for a reducer (in bytes):
INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>
INFO  : In order to limit the maximum number of reducers:
INFO  :   set hive.exec.reducers.max=<number>
INFO  : In order to set a constant number of reducers:
INFO  :   set mapreduce.job.reduces=<number>
INFO  : number of splits:1
INFO  : Submitting tokens for job: job_1705209094457_0003
INFO  : Executing with tokens: []
INFO  : The url to track the job: http://zgg-server:8088/proxy/application_1705209094457_0003/
INFO  : Starting Job = job_1705209094457_0003, Tracking URL = http://zgg-server:8088/proxy/application_1705209094457_0003/
INFO  : Kill Command = /opt/hadoop-3.3.6/bin/mapred job  -kill job_1705209094457_0003
INFO  : Hadoop job information for Stage-4: number of mappers: 1; number of reducers: 1
INFO  : 2024-01-14 05:29:28,282 Stage-4 map = 0%,  reduce = 0%
INFO  : 2024-01-14 05:29:36,766 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 1.63 sec
INFO  : 2024-01-14 05:29:47,294 Stage-4 map = 100%,  reduce = 100%, Cumulative CPU 4.74 sec
INFO  : MapReduce Total cumulative CPU time: 4 seconds 740 msec
INFO  : Ended Job = job_1705209094457_0003
INFO  : Launching Job 3 out of 4
INFO  : Starting task [Stage-5:MAPRED] in serial mode
INFO  : Number of reduce tasks not specified. Estimated from input data size: 1
INFO  : In order to change the average load for a reducer (in bytes):
INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>
INFO  : In order to limit the maximum number of reducers:
INFO  :   set hive.exec.reducers.max=<number>
INFO  : In order to set a constant number of reducers:
INFO  :   set mapreduce.job.reduces=<number>
INFO  : number of splits:1
INFO  : Submitting tokens for job: job_1705209094457_0004
INFO  : Executing with tokens: []
INFO  : The url to track the job: http://zgg-server:8088/proxy/application_1705209094457_0004/
INFO  : Starting Job = job_1705209094457_0004, Tracking URL = http://zgg-server:8088/proxy/application_1705209094457_0004/
INFO  : Kill Command = /opt/hadoop-3.3.6/bin/mapred job  -kill job_1705209094457_0004
INFO  : Hadoop job information for Stage-5: number of mappers: 1; number of reducers: 1
INFO  : 2024-01-14 05:30:06,879 Stage-5 map = 0%,  reduce = 0%
INFO  : 2024-01-14 05:30:17,479 Stage-5 map = 100%,  reduce = 0%, Cumulative CPU 3.3 sec
INFO  : 2024-01-14 05:30:29,036 Stage-5 map = 100%,  reduce = 100%, Cumulative CPU 7.88 sec
INFO  : MapReduce Total cumulative CPU time: 7 seconds 880 msec
INFO  : Ended Job = job_1705209094457_0004
INFO  : Starting task [Stage-1:MOVE] in serial mode
INFO  : Loading data to table default.t1_2 from hdfs://zgg-server:8020/user/hive/warehouse/t1_2/.hive-staging_hive_2024-01-14_05-27-06_406_5256501147906119415-2/-ext-10002
INFO  : Launching Job 4 out of 4
INFO  : Starting task [Stage-7:MAPRED] in serial mode
INFO  : Number of reduce tasks determined at compile time: 1
INFO  : In order to change the average load for a reducer (in bytes):
INFO  :   set hive.exec.reducers.bytes.per.reducer=<number>
INFO  : In order to limit the maximum number of reducers:
INFO  :   set hive.exec.reducers.max=<number>
INFO  : In order to set a constant number of reducers:
INFO  :   set mapreduce.job.reduces=<number>
INFO  : number of splits:1
INFO  : Submitting tokens for job: job_1705209094457_0005
INFO  : Executing with tokens: []
INFO  : The url to track the job: http://zgg-server:8088/proxy/application_1705209094457_0005/
INFO  : Starting Job = job_1705209094457_0005, Tracking URL = http://zgg-server:8088/proxy/application_1705209094457_0005/
INFO  : Kill Command = /opt/hadoop-3.3.6/bin/mapred job  -kill job_1705209094457_0005
INFO  : Hadoop job information for Stage-7: number of mappers: 1; number of reducers: 1
INFO  : 2024-01-14 05:30:46,638 Stage-7 map = 0%,  reduce = 0%
INFO  : 2024-01-14 05:30:54,012 Stage-7 map = 100%,  reduce = 0%, Cumulative CPU 1.53 sec
INFO  : 2024-01-14 05:31:05,681 Stage-7 map = 100%,  reduce = 100%, Cumulative CPU 4.9 sec
INFO  : MapReduce Total cumulative CPU time: 4 seconds 900 msec
INFO  : Ended Job = job_1705209094457_0005
INFO  : Starting task [Stage-3:STATS] in serial mode
INFO  : Executing stats task
INFO  : Table default.t1_1 stats: [numFiles=3, numRows=162542, totalSize=1676627, rawDataSize=1514085, numFilesErasureCoded=0]
INFO  : Starting task [Stage-6:STATS] in serial mode
INFO  : Executing stats task
INFO  : Table default.t1_2 stats: [numFiles=1, numRows=59048, totalSize=564222, rawDataSize=505174, numFilesErasureCoded=0]
INFO  : MapReduce Jobs Launched: 
INFO  : Stage-Stage-2: Map: 3  Reduce: 3   Cumulative CPU: 54.56 sec   HDFS Read: 678345862 HDFS Write: 5569541 HDFS EC Read: 0 SUCCESS
INFO  : Stage-Stage-4: Map: 1  Reduce: 1   Cumulative CPU: 4.74 sec   HDFS Read: 18185 HDFS Write: 1701 HDFS EC Read: 0 SUCCESS
INFO  : Stage-Stage-5: Map: 1  Reduce: 1   Cumulative CPU: 7.88 sec   HDFS Read: 3900407 HDFS Write: 565601 HDFS EC Read: 0 SUCCESS
INFO  : Stage-Stage-7: Map: 1  Reduce: 1   Cumulative CPU: 4.9 sec   HDFS Read: 15065 HDFS Write: 1700 HDFS EC Read: 0 SUCCESS
INFO  : Total MapReduce CPU Time Spent: 1 minutes 12 seconds 80 msec
INFO  : Completed executing command(queryId=root_20240114052706_5444ca32-0f8b-4990-bd03-c748f6cfa8a2); Time taken: 244.17 seconds
221,590 rows affected (244.942 seconds)
```