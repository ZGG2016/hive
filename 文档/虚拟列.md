# 虚拟列

[TOC]

- INPUT__FILE__NAME

	- 一个 mapper 任务的输入文件的名字

- BLOCK__OFFSET__INSIDE__FILE

	- 对于块压缩文件，它是当前块的文件偏移量，即当前块的第一个字节的在文件中的偏移量
	- 对于文本文件，显示当前行的第一个字节在文件中的偏移量
	- 主要用来排查有问题的输入数据

- ROW__OFFSET__INSIDE__BLOCK 

	- 对于块压缩文件，显示行号
	- 对于文本文件，显示为0
    - 若要显示它，必须设置 `set hive.exec.rowoffset=true`

- RAW__DATA__SIZE

- ROW__ID  [TODO](https://cwiki.apache.org/confluence/display/Hive/HCatalog+Streaming+Mutation+API)

- GROUPING__ID

	- 结果属于哪一个分组集合

## INPUT__FILE__NAME BLOCK__OFFSET__INSIDE__FILE ROW__OFFSET__INSIDE__BLOCK

```sql
--------------------- 对于文本文件 --------------------- 
-- 建表
create table apps (
id int,
app_name string,
url string,
country string
)
partitioned by (deal_day string)
row format delimited
fields terminated by ",";

-- 导数据
hive> load data local inpath '/mnt/sda4/data/app.txt' into table apps partition(deal_day='20220101');

hive> select * from apps;
apps.id apps.app_name   apps.url        apps.country    apps.deal_day
1       QQ APP  http://im.qq.com/       CN      20220101
2       微博 APP        http://weibo.com/       CN      20220101
3       淘宝 APP        https://www.taobao.com/ CN      20220101
4       FACEBOOK APP    https://www.facebook.com/       USA     20220101
5       GOOGLE  https://www.google.com/ USA     20220101
6       LINE    https://www.line.com/   JP      20220101

-- INPUT__FILE__NAME: 这行数据在哪个文件中，这个文件的名称及其路径
-- BLOCK__OFFSET__INSIDE__FILE: 一行的第一个字节在这个文件中的偏移量
-- ROW__OFFSET__INSIDE__BLOCK: 文本文件显示为0
hive> select id,INPUT__FILE__NAME,BLOCK__OFFSET__INSIDE__FILE,ROW__OFFSET__INSIDE__BLOCK from apps;
id      input__file__name       block__offset__inside__file     row__offset__inside__block
1       hdfs://bigdata101:9000/user/hive/warehouse/apps/deal_day=20220101/app.txt       0       0
2       hdfs://bigdata101:9000/user/hive/warehouse/apps/deal_day=20220101/app.txt       30      0
3       hdfs://bigdata101:9000/user/hive/warehouse/apps/deal_day=20220101/app.txt       64      0
4       hdfs://bigdata101:9000/user/hive/warehouse/apps/deal_day=20220101/app.txt       104     0
5       hdfs://bigdata101:9000/user/hive/warehouse/apps/deal_day=20220101/app.txt       149     0
6       hdfs://bigdata101:9000/user/hive/warehouse/apps/deal_day=20220101/app.txt       186     0
```


```sql
--------------------- 对于块压缩文件 --------------------- 
create table apps_rc (
id int,
app_name string,
url string,
country string
)
partitioned by (deal_day string)
row format delimited
stored as RCFile;

-- 插入数据
-- RCFile sequencefile 需要从textfile insert 插入
hive> insert into apps_rc partition(deal_day='20220101') select id,app_name,url,country from apps where deal_day='20220101';

hive> select * from apps_rc;
apps_rc.id      apps_rc.app_name        apps_rc.url     apps_rc.country apps_rc.deal_day
1       QQ APP  http://im.qq.com/       CN      20220101
2       微博 APP        http://weibo.com/       CN      20220101
3       淘宝 APP        https://www.taobao.com/ CN      20220101
4       FACEBOOK APP    https://www.facebook.com/       USA     20220101
5       GOOGLE  https://www.google.com/ USA     20220101
6       LINE    https://www.line.com/   JP      20220101


-- INPUT__FILE__NAME: 这行数据在哪个文件中，这个文件的名称及其路径
-- BLOCK__OFFSET__INSIDE__FILE: 当前块的文件偏移量，即当前块的第一个字节的在文件中的偏移量
-- ROW__OFFSET__INSIDE__BLOCK: 显示行号
hive> select id,INPUT__FILE__NAME,BLOCK__OFFSET__INSIDE__FILE,ROW__OFFSET__INSIDE__BLOCK from apps_rc;
id      input__file__name       block__offset__inside__file     row__offset__inside__block
1       hdfs://bigdata101:9000/user/hive/warehouse/apps_rc/deal_day=20220101/000000_0   56      0
2       hdfs://bigdata101:9000/user/hive/warehouse/apps_rc/deal_day=20220101/000000_0   56      1
3       hdfs://bigdata101:9000/user/hive/warehouse/apps_rc/deal_day=20220101/000000_0   56      2
4       hdfs://bigdata101:9000/user/hive/warehouse/apps_rc/deal_day=20220101/000000_0   56      3
5       hdfs://bigdata101:9000/user/hive/warehouse/apps_rc/deal_day=20220101/000000_0   56      4
6       hdfs://bigdata101:9000/user/hive/warehouse/apps_rc/deal_day=20220101/000000_0   56      5
```

```sql
--------------------- 对于文本文件 --------------------- 
-- 再往apps表里插入数据
hive> load data local inpath '/mnt/sda4/data/app2.txt' into table apps partition(deal_day='20220102');

hive> select * from apps;
apps.id apps.app_name   apps.url        apps.country    apps.deal_day
1       QQ APP  http://im.qq.com/       CN      20220101
2       微博 APP        http://weibo.com/       CN      20220101
3       淘宝 APP        https://www.taobao.com/ CN      20220101
4       FACEBOOK APP    https://www.facebook.com/       USA     20220101
5       GOOGLE  https://www.google.com/ USA     20220101
6       LINE    https://www.line.com/   JP      20220101
1       wechat  http://www.wechat.com/  CN      20220102
2       jingdong        http://www.jingdong.com/        CN      20220102

-- INPUT__FILE__NAME: 这行数据在哪个文件中，这个文件的名称及其路径
-- BLOCK__OFFSET__INSIDE__FILE: 一行的第一个字节在这个文件中的偏移量
-- ROW__OFFSET__INSIDE__BLOCK: 文本文件显示为0
hive> select id,INPUT__FILE__NAME,BLOCK__OFFSET__INSIDE__FILE,ROW__OFFSET__INSIDE__BLOCK from apps;
id      input__file__name       block__offset__inside__file     row__offset__inside__block
1       hdfs://bigdata101:9000/user/hive/warehouse/apps/deal_day=20220101/app.txt       0       0
2       hdfs://bigdata101:9000/user/hive/warehouse/apps/deal_day=20220101/app.txt       30      0
3       hdfs://bigdata101:9000/user/hive/warehouse/apps/deal_day=20220101/app.txt       64      0
4       hdfs://bigdata101:9000/user/hive/warehouse/apps/deal_day=20220101/app.txt       104     0
5       hdfs://bigdata101:9000/user/hive/warehouse/apps/deal_day=20220101/app.txt       149     0
6       hdfs://bigdata101:9000/user/hive/warehouse/apps/deal_day=20220101/app.txt       186     0
1       hdfs://bigdata101:9000/user/hive/warehouse/apps/deal_day=20220102/app2.txt      0       0
2       hdfs://bigdata101:9000/user/hive/warehouse/apps/deal_day=20220102/app2.txt      35      0
```

```sql
--------------------- 对于块压缩文件 --------------------- 
-- 插入数据
hive> insert into apps_rc partition(deal_day='20220102') select id,app_name,url,country from apps where deal_day='20220102';

hive> select * from apps_rc;
apps_rc.id      apps_rc.app_name        apps_rc.url     apps_rc.country apps_rc.deal_day
1       QQ APP  http://im.qq.com/       CN      20220101
2       微博 APP        http://weibo.com/       CN      20220101
3       淘宝 APP        https://www.taobao.com/ CN      20220101
4       FACEBOOK APP    https://www.facebook.com/       USA     20220101
5       GOOGLE  https://www.google.com/ USA     20220101
6       LINE    https://www.line.com/   JP      20220101
1       wechat  http://www.wechat.com/  CN      20220102
2       jingdong        http://www.jingdong.com/        CN      20220102

-- INPUT__FILE__NAME: 这行数据在哪个文件中，这个文件的名称及其路径
-- BLOCK__OFFSET__INSIDE__FILE: 当前块的文件偏移量，即当前块的第一个字节的在文件中的偏移量
-- ROW__OFFSET__INSIDE__BLOCK: 显示行号
hive> select id,INPUT__FILE__NAME,BLOCK__OFFSET__INSIDE__FILE,ROW__OFFSET__INSIDE__BLOCK from apps_rc;
id      input__file__name       block__offset__inside__file     row__offset__inside__block
1       hdfs://bigdata101:9000/user/hive/warehouse/apps_rc/deal_day=20220101/000000_0   56      0
2       hdfs://bigdata101:9000/user/hive/warehouse/apps_rc/deal_day=20220101/000000_0   56      1
3       hdfs://bigdata101:9000/user/hive/warehouse/apps_rc/deal_day=20220101/000000_0   56      2
4       hdfs://bigdata101:9000/user/hive/warehouse/apps_rc/deal_day=20220101/000000_0   56      3
5       hdfs://bigdata101:9000/user/hive/warehouse/apps_rc/deal_day=20220101/000000_0   56      4
6       hdfs://bigdata101:9000/user/hive/warehouse/apps_rc/deal_day=20220101/000000_0   56      5
1       hdfs://bigdata101:9000/user/hive/warehouse/apps_rc/deal_day=20220102/000000_0   294     0
2       hdfs://bigdata101:9000/user/hive/warehouse/apps_rc/deal_day=20220102/000000_0   56      0
```

## GROUPING__ID

```sql
-- 在一个 GROUP BY 查询中，根据不同的维度组合进行聚合，等价于将不同维度的 GROUP BY 结果集进行 UNION ALL。
SELECT a, b, SUM(c) FROM tab1 GROUP BY a, b GROUPING SETS ((a,b),a,b,())	

-- 等价于：
SELECT a, b, SUM(c) FROM tab1 GROUP BY a, b 
UNION ALL 
SELECT a, null, SUM(c) FROM tab1 GROUP BY a 
UNION ALL 
SELECT null, b, SUM(c) FROM tab1 GROUP BY b 
UNION ALL 
SELECT null, null, SUM(c) FROM tab1
```

```sql
hive> select * from apps;
OK
1       'QQ APP'        'http://im.qq.com/'     'CN'
2       '微博 APP'      'http://weibo.com/'     'CN'
3       '淘宝 APP'      'https://www.taobao.com/'       'CN'
4       'FACEBOOK APP'  'https://www.facebook.com/'     'USA'
5       'GOOGLE'        'https://www.google.com/'       'USA'
6       'LINE'  'https://www.line.com/' 'JP'

-- GROUPING__ID，表示结果属于哪一个分组集合
hive> select country,count(*),GROUPING__ID from apps group by country grouping sets(country);
....
OK
'CN'    3       0
'JP'    1       0
'USA'   2       0

-- 指定分组编号 
hive> select country,count(*),1 as GROUPING__ID from apps group by country;
....
OK
'CN'    3       1
'JP'    1       1
'USA'   2       1
Time taken: 75.912 seconds, Fetched: 3 row(s)

-- (id,country)-0，id-1，country-2
hive> select id,country,count(*),GROUPING__ID from apps group by id,country grouping sets(id,country,(id,country)) order by GROUPING__ID;
OK
3       'CN'    1       0
6       'JP'    1       0
2       'CN'    1       0
4       'USA'   1       0
1       'CN'    1       0
5       'USA'   1       0
3       NULL    1       1
6       NULL    1       1
5       NULL    1       1
4       NULL    1       1
2       NULL    1       1
1       NULL    1       1
NULL    'USA'   2       2
NULL    'JP'    1       2
NULL    'CN'    3       2
```

参考：[https://www.cnblogs.com/qingyunzong/p/8798987.html](https://www.cnblogs.com/qingyunzong/p/8798987.html)

[点这里](https://github.com/ZGG2016/hive/blob/master/%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E8%AF%91%E6%96%87/User%20Documentation/Hive%20SQL%20Language%20Manual/Enhanced%20Aggregation%2C%20Cube%2C%20Grouping%20and%20Rollup.md) 查看关于 grouping_id 的更多描述