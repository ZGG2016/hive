# 分区表和数据产生关联

[TOC]

把数据直接上传到分区目录上，让分区表和数据产生关联的三种方式。
 
## 1 方式一：上传数据后修复

```
hive (default)> dfs -mkdir -p /user/hive/warehouse/mydb.db/dept_partition2/day=20200401/hour=13;

hive (default)> dfs -put /opt/module/datas/dept_20200401.log /user/hive/warehouse/mydb.db/dept_partition2/day=20200401/hour=13;
```

查询数据（查询不到刚上传的数据）

```
hive (default)> select * from dept_partition2 where day='20200401' and hour='13';
```

执行修复命令

```
hive> msck repair table dept_partition2;
```

再次查询数据

```
hive (default)> select * from dept_partition2 where day='20200401' and hour='13';
```


## 2 方式二：上传数据后添加分区

```
hive (default)> dfs -mkdir -p /user/hive/warehouse/mydb.db/dept_partition2/day=20200401/hour=14;

hive (default)> dfs -put /opt/module/hive/datas/dept_20200401.log /user/hive/warehouse/mydb.db/dept_partition2/day=20200401/hour=14;
```

执行添加分区

```
hive (default)> alter table dept_partition2 add partition(day='201709',hour='14');
```

查询数据

```
hive (default)> select * from dept_partition2 where day='20200401' and hour='14';
```

## 3 方式三：创建文件夹后 load 数据到分区

创建目录

```
hive (default)> dfs -mkdir -p /user/hive/warehouse/mydb.db/dept_partition2/day=20200401/hour=15;
```

上传数据

```
hive (default)> load data local inpath '/opt/module/hive/datas/dept_20200401.log' into table dept_partition2 partition(day='20200401',hour='15');
```

查询数据

```
hive (default)> select * from dept_partition2 where day='20200401' and hour='15';
```

来自：[尚硅谷hive教程](https://www.bilibili.com/video/BV1EZ4y1G7iL)