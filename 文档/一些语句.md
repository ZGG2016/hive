# 一些语句

[TOC]

## Multi Table/File Inserts

聚合或简单选择的输出可以进一步发送到多个表中，甚至发送到 hadoop dfs 文件中(然后可以使用 hdfs 实用程序操作这些文件)。

```sql
0: jdbc:hive2://localhost:10000> create table t1(id int, name string, age int, salary double);

0: jdbc:hive2://localhost:10000> insert into t1 values(1,"aa","24", 3000.00),(2,"bb","33", 8000.00),(3,"cc","44", 10000.00);  

0: jdbc:hive2://localhost:10000> select * from t1;
+--------+----------+---------+------------+
| t1.id  | t1.name  | t1.age  | t1.salary  |
+--------+----------+---------+------------+
| 1      | aa       | 24      | 3000.0     |
| 2      | bb       | 33      | 8000.0     |
| 3      | cc       | 44      | 10000.0    |
+--------+----------+---------+------------+

0: jdbc:hive2://localhost:10000> create table t1_1(id int, cnt int);
0: jdbc:hive2://localhost:10000> create table t1_2(name string, salary double);
```

```sql
from t1
insert overwrite table t1_1
select t1.id, count(distinct t1.name) cnt
 group by t1.id
-- insert overwrite DIRECTORY '/user/hive/warehouse/t1_2'
insert overwrite table t1_2
select t1.name,sum(t1.salary) salary
 group by t1.name;

0: jdbc:hive2://localhost:10000> select * from t1_1;
+----------+-----------+
| t1_1.id  | t1_1.cnt  |
+----------+-----------+
| 1        | 1         |
| 2        | 1         |
| 3        | 1         |
+----------+-----------+

0: jdbc:hive2://localhost:10000> select * from t1_2;
+------------+--------------+
| t1_2.name  | t1_2.salary  |
+------------+--------------+
| aa         | 3000.0       |
| bb         | 8000.0       |
| cc         | 10000.0      |
+------------+--------------+
```

## Inserting into Local Files

在某些情况下，可能希望将输出写入到本地文件，以便将其加载到 excel 表格中

```sql
INSERT OVERWRITE LOCAL DIRECTORY '/opt/hive/test-data/t1_local'
SELECT t1.*
FROM t1;

hive@8361ca1351e2:/opt/hive/test-data$ ls t1_local/
000000_0      
hive@8361ca1351e2:/opt/hive/test-data$ cat t1_local/000000_0 
1aa243000.0
2bb338000.0
3cc4410000.0
4dd347000.0
4dd347000.0
```

## 在 Hive shell 中执行一个 shell 命令

```
hive> !ls /root;
anaconda-ks.cfg
data
jar
python_script
run_env
script
sql_script
```

## 在 Hive shell 中执行一个 dfs 命令

```
hive> dfs -cat /in/calavg.txt;
A,math,70
B,math,80
C,math,90
A,science,88
B,science,86
C,science,90
```

## 在 CLI 中执行脚本文件

```
hive@8361ca1351e2:/opt/hive/test-data$ cat hive.sql 
show tables

0: jdbc:hive2://localhost:10000> source /opt/hive/test-data/hive.sql;
+---------------------------+
|         tab_name          |
+---------------------------+
| constraints1              |
| constraints2              |
| constraints22             |
| constraints3              |
| fk                        |
| movies_data               |
...
```
